{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "# from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu118\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)           # Check PyTorch version\n",
    "print(torch.version.cuda)          # Check CUDA version PyTorch was compiled with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be74b9e2c1e44e5093c84f4aa034d9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you want more control, you will need to define the tokenizer and model.\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", torch_dtype=torch.float16, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference using pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer = tokenizer, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the pros and cons of AI.\n",
      "\n",
      "Artificial intelligence is a rapidly growing field with many benefits and drawbacks. On one hand, AI has the potential to revolutionize industries and improve our lives in countless ways. On the other hand, there are concerns about the potential negative impacts of AI on society. In this blog post, we will explore the pros and cons of AI and discuss what the future holds for this powerful technology.\n",
      "\n",
      "The Pros of AI:\n",
      "\n",
      "1. Improved Efficiency and Productivity\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Explain the pros and cons of AI\"\n",
    "sequences = pipe(\n",
    "    prompt,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=100, \n",
    "    temperature=0.7, \n",
    "    top_k=50, \n",
    "    top_p=0.95,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "print(sequences[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain the pros and cons of AI\"\n",
    "sequences = pipe(\n",
    "    prompt,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=100, \n",
    "    temperature=0.7, \n",
    "    top_k=50, \n",
    "    top_p=0.95,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "print(sequences[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me the overview of Mistral\n",
      "\n",
      "Mistral is the world’s first open source, full-stack data platform that delivers the power and flexibility of the cloud to any enterprise. With Mistral, any enterprise can build their own data platform on-premises or in the cloud with the same scale, availability, security and performance of the best cloud data platforms.\n",
      "\n",
      "How is Mistral different from other solutions in the market?\n",
      "\n",
      "Mistral is the world’s first and only full-\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Give me the overview of Mistral\"\n",
    "sequences = pipe(\n",
    "    prompt,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=100, \n",
    "    temperature=0.7, \n",
    "    top_k=50, \n",
    "    top_p=0.95,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "print(sequences[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is hate speech? How is it defined? When does it become a crime? In a recent post we examined hate speech as a form of discrimination, but hate speech has legal implications as well.\n",
      "\n",
      "Hate speech is a broad term that encompasses a wide variety of discriminatory comments or behavior. It can be written, spoken or broadcast and can be targeted towards a specific group or individual. Hate speech can be used to dehumanize, humiliate, or intimidate a person or group\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt = \"What is hate speech?\"\n",
    "\n",
    "sequences = pipe(\n",
    "    prompt,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=100, \n",
    "    temperature=0.7, \n",
    "    top_k=50, \n",
    "    top_p=0.95,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "print(sequences[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19 (main, May  6 2024, 19:43:03) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "13cbab73567c1bd594493c0dbc10dff52949031274552f5498bec08ae58d7886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
