Loading checkpoint from checkpoints/checkpoint-14415...
checkpoints/checkpoint-14415
Accuracy on valid predictions: 0.70

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.74      0.83      0.79       593
      normal       0.74      0.76      0.75       781
   offensive       0.58      0.48      0.52       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.70      1922
   macro avg       0.51      0.52      0.51      1922
weighted avg       0.69      0.70      0.70      1922

{'average_precision': 0.6969302809573362, 'average_recall': 0.6794138050641692, 'overall_precision': 0.6930033317467873, 'overall_recall': 0.7037216046399226, 'f1_score': 0.6983213429256595, 'per_label_precision': {'african': 0.8295819935691319, 'arab': 0.6904761904761905, 'asian': 0.6774193548387096, 'caucasian': 0.6363636363636364, 'christian': 0.0, 'hispanic': 0.75, 'buddhism': 0, 'hindu': 0, 'islam': 0.8173076923076923, 'jewish': 0.8743455497382199, 'men': 0.14285714285714285, 'women': 0.5, 'heterosexual': 0, 'homosexual': 0.7588235294117647, 'indigenous': 0, 'refugee': 0.5632183908045977, 'immigrant': 0, 'disability': 0.3333333333333333, 'none': 0.7066869300911854}, 'per_label_recall': {'african': 0.832258064516129, 'arab': 0.7532467532467533, 'asian': 0.6176470588235294, 'caucasian': 0.2916666666666667, 'christian': 0.0, 'hispanic': 0.7714285714285715, 'buddhism': 0, 'hindu': 0, 'islam': 0.8333333333333334, 'jewish': 0.8978494623655914, 'men': 0.16666666666666666, 'women': 0.5496688741721855, 'heterosexual': 0, 'homosexual': 0.7087912087912088, 'indigenous': 0, 'refugee': 0.6363636363636364, 'immigrant': 0, 'disability': 0.25, 'none': 0.6961077844311377}, 'per_label_f1': {'african': 0.8309178743961354, 'arab': 0.7204968944099378, 'asian': 0.6461538461538462, 'caucasian': 0.4, 'christian': 0, 'hispanic': 0.7605633802816902, 'buddhism': 0, 'hindu': 0, 'islam': 0.825242718446602, 'jewish': 0.8859416445623343, 'men': 0.15384615384615383, 'women': 0.5236593059936909, 'heterosexual': 0, 'homosexual': 0.7329545454545454, 'indigenous': 0, 'refugee': 0.5975609756097561, 'immigrant': 0, 'disability': 0.28571428571428575, 'none': 0.7013574660633485}, 'macro_precision': 0.4358112496732423, 'macro_recall': 0.42131726741081105, 'macro_f1_score': 0.4244425837332803}
Loading checkpoint from checkpoints/checkpoint-19220...
checkpoints/checkpoint-19220
Accuracy on valid predictions: 0.67

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.77      0.72      0.74       593
      normal       0.74      0.70      0.72       781
   offensive       0.50      0.58      0.54       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.67      1922
   macro avg       0.50      0.50      0.50      1922
weighted avg       0.68      0.67      0.67      1922

{'average_precision': 0.6828910856746446, 'average_recall': 0.6766215747485257, 'overall_precision': 0.680129990714949, 'overall_recall': 0.7080715321411309, 'f1_score': 0.6938195595548189, 'per_label_precision': {'african': 0.8178913738019169, 'arab': 0.6875, 'asian': 0.5897435897435898, 'caucasian': 0.425531914893617, 'christian': 0.0, 'hispanic': 0.7368421052631579, 'buddhism': 0, 'hindu': 0, 'islam': 0.8, 'jewish': 0.8365384615384616, 'men': 0.0, 'women': 0.5333333333333333, 'heterosexual': 0, 'homosexual': 0.7448979591836735, 'indigenous': 0, 'refugee': 0.6578947368421053, 'immigrant': 0, 'disability': 0.0, 'none': 0.7007633587786259}, 'per_label_recall': {'african': 0.8258064516129032, 'arab': 0.7142857142857143, 'asian': 0.6764705882352942, 'caucasian': 0.4166666666666667, 'christian': 0.0, 'hispanic': 0.8, 'buddhism': 0, 'hindu': 0, 'islam': 0.8431372549019608, 'jewish': 0.9354838709677419, 'men': 0.0, 'women': 0.4768211920529801, 'heterosexual': 0, 'homosexual': 0.8021978021978022, 'indigenous': 0, 'refugee': 0.6493506493506493, 'immigrant': 0, 'disability': 0.0, 'none': 0.687125748502994}, 'per_label_f1': {'african': 0.8218298555377207, 'arab': 0.7006369426751592, 'asian': 0.6301369863013699, 'caucasian': 0.42105263157894735, 'christian': 0, 'hispanic': 0.7671232876712328, 'buddhism': 0, 'hindu': 0, 'islam': 0.8210023866348449, 'jewish': 0.883248730964467, 'men': 0, 'women': 0.5034965034965034, 'heterosexual': 0, 'homosexual': 0.7724867724867726, 'indigenous': 0, 'refugee': 0.6535947712418301, 'immigrant': 0, 'disability': 0, 'none': 0.6938775510204082}, 'macro_precision': 0.3963650964936043, 'macro_recall': 0.41196557572498455, 'macro_f1_score': 0.40360454840048715}
Loading checkpoint from checkpoints/checkpoint-24025...
checkpoints/checkpoint-24025
Accuracy on valid predictions: 0.69

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.75      0.80      0.77       593
      normal       0.79      0.67      0.73       781
   offensive       0.54      0.61      0.57       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.69      1922
   macro avg       0.52      0.52      0.52      1922
weighted avg       0.71      0.69      0.70      1922

{'average_precision': 0.6858914325355533, 'average_recall': 0.6645508151231355, 'overall_precision': 0.6844124700239809, 'overall_recall': 0.6897051715804736, 'f1_score': 0.687048627828599, 'per_label_precision': {'african': 0.8068535825545171, 'arab': 0.6923076923076923, 'asian': 0.575, 'caucasian': 0.5384615384615384, 'christian': 0, 'hispanic': 0.7368421052631579, 'buddhism': 0, 'hindu': 0, 'islam': 0.8307692307692308, 'jewish': 0.8950276243093923, 'men': 0.0, 'women': 0.5531914893617021, 'heterosexual': 0, 'homosexual': 0.7254901960784313, 'indigenous': 0, 'refugee': 0.6666666666666666, 'immigrant': 0, 'disability': 0.5, 'none': 0.7149837133550488}, 'per_label_recall': {'african': 0.8354838709677419, 'arab': 0.5844155844155844, 'asian': 0.6764705882352942, 'caucasian': 0.2916666666666667, 'christian': 0.0, 'hispanic': 0.8, 'buddhism': 0, 'hindu': 0, 'islam': 0.7941176470588235, 'jewish': 0.8709677419354839, 'men': 0.0, 'women': 0.5165562913907285, 'heterosexual': 0, 'homosexual': 0.8131868131868132, 'indigenous': 0, 'refugee': 0.7012987012987013, 'immigrant': 0, 'disability': 0.25, 'none': 0.657185628742515}, 'per_label_f1': {'african': 0.820919175911252, 'arab': 0.6338028169014084, 'asian': 0.6216216216216216, 'caucasian': 0.3783783783783784, 'christian': 0, 'hispanic': 0.7671232876712328, 'buddhism': 0, 'hindu': 0, 'islam': 0.8120300751879699, 'jewish': 0.8828337874659401, 'men': 0, 'women': 0.5342465753424657, 'heterosexual': 0, 'homosexual': 0.766839378238342, 'indigenous': 0, 'refugee': 0.6835443037974684, 'immigrant': 0, 'disability': 0.3333333333333333, 'none': 0.6848673946957878}, 'macro_precision': 0.4334523073224936, 'macro_recall': 0.4100710280999133, 'macro_f1_score': 0.41681790150237896}
Loading checkpoint from checkpoints/checkpoint-28830...
checkpoints/checkpoint-28830
Accuracy on valid predictions: 0.70

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.73      0.83      0.77       593
      normal       0.78      0.73      0.75       781
   offensive       0.56      0.52      0.54       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.70      1922
   macro avg       0.52      0.52      0.52      1922
weighted avg       0.70      0.70      0.70      1922

{'average_precision': 0.707032604925425, 'average_recall': 0.6965227193895248, 'overall_precision': 0.6989346919870311, 'overall_recall': 0.7293378443692605, 'f1_score': 0.7138126773888364, 'per_label_precision': {'african': 0.7850746268656716, 'arab': 0.6962025316455697, 'asian': 0.6285714285714286, 'caucasian': 0.4262295081967213, 'christian': 0.2, 'hispanic': 0.7222222222222222, 'buddhism': 0, 'hindu': 0, 'islam': 0.7837837837837838, 'jewish': 0.8647342995169082, 'men': 0.6666666666666666, 'women': 0.5570469798657718, 'heterosexual': 0, 'homosexual': 0.7397959183673469, 'indigenous': 0, 'refugee': 0.6129032258064516, 'immigrant': 0, 'disability': 0.0, 'none': 0.7254290171606864}, 'per_label_recall': {'african': 0.8483870967741935, 'arab': 0.7142857142857143, 'asian': 0.6470588235294118, 'caucasian': 0.5416666666666666, 'christian': 0.3333333333333333, 'hispanic': 0.7428571428571429, 'buddhism': 0, 'hindu': 0, 'islam': 0.8529411764705882, 'jewish': 0.9623655913978495, 'men': 0.3333333333333333, 'women': 0.5496688741721855, 'heterosexual': 0, 'homosexual': 0.7967032967032966, 'indigenous': 0, 'refugee': 0.7402597402597403, 'immigrant': 0, 'disability': 0.0, 'none': 0.6961077844311377}, 'per_label_f1': {'african': 0.8155038759689922, 'arab': 0.7051282051282052, 'asian': 0.6376811594202899, 'caucasian': 0.47706422018348627, 'christian': 0.25, 'hispanic': 0.732394366197183, 'buddhism': 0, 'hindu': 0, 'islam': 0.8169014084507041, 'jewish': 0.9109414758269722, 'men': 0.4444444444444444, 'women': 0.5533333333333335, 'heterosexual': 0, 'homosexual': 0.7671957671957672, 'indigenous': 0, 'refugee': 0.6705882352941177, 'immigrant': 0, 'disability': 0, 'none': 0.7104660045836517}, 'macro_precision': 0.44256106361417, 'macro_recall': 0.4609983460112944, 'macro_f1_score': 0.4469285524224814}
Loading checkpoint from checkpoints/checkpoint-33635...
checkpoints/checkpoint-33635
Accuracy on valid predictions: 0.69

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.75      0.78      0.76       593
      normal       0.76      0.73      0.74       781
   offensive       0.53      0.54      0.53       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.69      1922
   macro avg       0.51      0.51      0.51      1922
weighted avg       0.69      0.69      0.69      1922

{'average_precision': 0.6855012140131806, 'average_recall': 0.6835067637877211, 'overall_precision': 0.6810661764705882, 'overall_recall': 0.7162880618656355, 'f1_score': 0.6982332155477032, 'per_label_precision': {'african': 0.8105590062111802, 'arab': 0.6705882352941176, 'asian': 0.6097560975609756, 'caucasian': 0.34146341463414637, 'christian': 0.0, 'hispanic': 0.7777777777777778, 'buddhism': 0, 'hindu': 0, 'islam': 0.788546255506608, 'jewish': 0.845, 'men': 0.0, 'women': 0.5, 'heterosexual': 0, 'homosexual': 0.7966101694915254, 'indigenous': 0, 'refugee': 0.59375, 'immigrant': 0, 'disability': 0.0, 'none': 0.6857562408223201}, 'per_label_recall': {'african': 0.8419354838709677, 'arab': 0.7402597402597403, 'asian': 0.7352941176470589, 'caucasian': 0.2916666666666667, 'christian': 0.0, 'hispanic': 0.8, 'buddhism': 0, 'hindu': 0, 'islam': 0.8774509803921569, 'jewish': 0.9086021505376344, 'men': 0.0, 'women': 0.5033112582781457, 'heterosexual': 0, 'homosexual': 0.7747252747252747, 'indigenous': 0, 'refugee': 0.7402597402597403, 'immigrant': 0, 'disability': 0.0, 'none': 0.6991017964071856}, 'per_label_f1': {'african': 0.8259493670886076, 'arab': 0.7037037037037037, 'asian': 0.6666666666666666, 'caucasian': 0.31460674157303375, 'christian': 0, 'hispanic': 0.7887323943661971, 'buddhism': 0, 'hindu': 0, 'islam': 0.8306264501160092, 'jewish': 0.8756476683937824, 'men': 0, 'women': 0.5016501650165017, 'heterosexual': 0, 'homosexual': 0.7855153203342619, 'indigenous': 0, 'refugee': 0.6589595375722545, 'immigrant': 0, 'disability': 0, 'none': 0.69236471460341}, 'macro_precision': 0.3905161682788763, 'macro_recall': 0.41645301100234583, 'macro_f1_score': 0.4023380383912857}
Loading checkpoint from checkpoints/checkpoint-38440...
checkpoints/checkpoint-38440
Accuracy on valid predictions: 0.68

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.69      0.85      0.77       593
      normal       0.77      0.68      0.72       781
   offensive       0.55      0.51      0.53       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.68      1922
   macro avg       0.50      0.51      0.50      1922
weighted avg       0.68      0.68      0.68      1922

{'average_precision': 0.6979535206382241, 'average_recall': 0.6894640998959418, 'overall_precision': 0.6924144310823311, 'overall_recall': 0.7235379410343161, 'f1_score': 0.7076341290475066, 'per_label_precision': {'african': 0.8113207547169812, 'arab': 0.7126436781609196, 'asian': 0.6097560975609756, 'caucasian': 0.3442622950819672, 'christian': 0.0, 'hispanic': 0.7435897435897436, 'buddhism': 0, 'hindu': 0, 'islam': 0.7972350230414746, 'jewish': 0.8446601941747572, 'men': 0.0, 'women': 0.4794520547945205, 'heterosexual': 0, 'homosexual': 0.7584541062801933, 'indigenous': 0, 'refugee': 0.6627906976744186, 'immigrant': 0, 'disability': 0.0, 'none': 0.7021276595744681}, 'per_label_recall': {'african': 0.832258064516129, 'arab': 0.8051948051948052, 'asian': 0.7352941176470589, 'caucasian': 0.4375, 'christian': 0.0, 'hispanic': 0.8285714285714286, 'buddhism': 0, 'hindu': 0, 'islam': 0.8480392156862745, 'jewish': 0.9354838709677419, 'men': 0.0, 'women': 0.46357615894039733, 'heterosexual': 0, 'homosexual': 0.8626373626373627, 'indigenous': 0, 'refugee': 0.7402597402597403, 'immigrant': 0, 'disability': 0.0, 'none': 0.6916167664670658}, 'per_label_f1': {'african': 0.821656050955414, 'arab': 0.7560975609756099, 'asian': 0.6666666666666666, 'caucasian': 0.3853211009174312, 'christian': 0, 'hispanic': 0.7837837837837838, 'buddhism': 0, 'hindu': 0, 'islam': 0.8218527315914489, 'jewish': 0.8877551020408163, 'men': 0, 'women': 0.47138047138047134, 'heterosexual': 0, 'homosexual': 0.8071979434447301, 'indigenous': 0, 'refugee': 0.6993865030674846, 'immigrant': 0, 'disability': 0, 'none': 0.6968325791855203}, 'macro_precision': 0.3929627528763378, 'macro_recall': 0.430549027941474, 'macro_f1_score': 0.4104173944215462}
Loading checkpoint from checkpoints/checkpoint-43245...
checkpoints/checkpoint-43245
Accuracy on valid predictions: 0.69

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.74      0.78      0.76       593
      normal       0.72      0.76      0.74       781
   offensive       0.55      0.48      0.51       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.69      1922
   macro avg       0.50      0.50      0.50      1922
weighted avg       0.68      0.69      0.68      1922

{'average_precision': 0.6994797086368367, 'average_recall': 0.692698577870274, 'overall_precision': 0.6931608133086876, 'overall_recall': 0.7249879168680522, 'f1_score': 0.7087172218284903, 'per_label_precision': {'african': 0.7827380952380952, 'arab': 0.6951219512195121, 'asian': 0.5757575757575758, 'caucasian': 0.45454545454545453, 'christian': 0.0, 'hispanic': 0.7941176470588235, 'buddhism': 0, 'hindu': 0, 'islam': 0.7906976744186046, 'jewish': 0.8431372549019608, 'men': 0.0, 'women': 0.5165562913907285, 'heterosexual': 0, 'homosexual': 0.765625, 'indigenous': 0, 'refugee': 0.6341463414634146, 'immigrant': 0, 'disability': 0.0, 'none': 0.6757865937072504}, 'per_label_recall': {'african': 0.8483870967741935, 'arab': 0.7402597402597403, 'asian': 0.5588235294117647, 'caucasian': 0.3125, 'christian': 0.0, 'hispanic': 0.7714285714285715, 'buddhism': 0, 'hindu': 0, 'islam': 0.8333333333333334, 'jewish': 0.9247311827956989, 'men': 0.0, 'women': 0.5165562913907285, 'heterosexual': 0, 'homosexual': 0.8076923076923077, 'indigenous': 0, 'refugee': 0.6753246753246753, 'immigrant': 0, 'disability': 0.0, 'none': 0.7395209580838323}, 'per_label_f1': {'african': 0.8142414860681115, 'arab': 0.7169811320754716, 'asian': 0.5671641791044776, 'caucasian': 0.3703703703703703, 'christian': 0, 'hispanic': 0.782608695652174, 'buddhism': 0, 'hindu': 0, 'islam': 0.8114558472553699, 'jewish': 0.882051282051282, 'men': 0, 'women': 0.5165562913907285, 'heterosexual': 0, 'homosexual': 0.786096256684492, 'indigenous': 0, 'refugee': 0.6540880503144655, 'immigrant': 0, 'disability': 0, 'none': 0.7062187276626162}, 'macro_precision': 0.3962226252474431, 'macro_recall': 0.4067661940260445, 'macro_f1_score': 0.4004122272962925}
Loading checkpoint from checkpoints/checkpoint-4805...
checkpoints/checkpoint-4805
Accuracy on valid predictions: 0.72

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.76      0.83      0.79       593
      normal       0.79      0.73      0.76       781
   offensive       0.58      0.58      0.58       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.72      1922
   macro avg       0.53      0.54      0.53      1922
weighted avg       0.72      0.72      0.72      1922

{'average_precision': 0.7134061741241761, 'average_recall': 0.7006937218175511, 'overall_precision': 0.7097836312323612, 'overall_recall': 0.7293378443692605, 'f1_score': 0.7194278903456496, 'per_label_precision': {'african': 0.8388157894736842, 'arab': 0.7125, 'asian': 0.6363636363636364, 'caucasian': 0.5862068965517241, 'christian': 0.25, 'hispanic': 0.7222222222222222, 'buddhism': 0, 'hindu': 0, 'islam': 0.8252427184466019, 'jewish': 0.8636363636363636, 'men': 0.25, 'women': 0.6074766355140186, 'heterosexual': 0, 'homosexual': 0.7589743589743589, 'indigenous': 0, 'refugee': 0.6136363636363636, 'immigrant': 0, 'disability': 0.0, 'none': 0.6758530183727034}, 'per_label_recall': {'african': 0.8225806451612904, 'arab': 0.7402597402597403, 'asian': 0.6176470588235294, 'caucasian': 0.3541666666666667, 'christian': 0.3333333333333333, 'hispanic': 0.7428571428571429, 'buddhism': 0, 'hindu': 0, 'islam': 0.8333333333333334, 'jewish': 0.9193548387096774, 'men': 0.16666666666666666, 'women': 0.4304635761589404, 'heterosexual': 0, 'homosexual': 0.8131868131868132, 'indigenous': 0, 'refugee': 0.7012987012987013, 'immigrant': 0, 'disability': 0.0, 'none': 0.7709580838323353}, 'per_label_f1': {'african': 0.8306188925081434, 'arab': 0.7261146496815287, 'asian': 0.6268656716417911, 'caucasian': 0.4415584415584416, 'christian': 0.28571428571428575, 'hispanic': 0.732394366197183, 'buddhism': 0, 'hindu': 0, 'islam': 0.8292682926829268, 'jewish': 0.890625, 'men': 0.2, 'women': 0.5038759689922481, 'heterosexual': 0, 'homosexual': 0.7851458885941645, 'indigenous': 0, 'refugee': 0.6545454545454544, 'immigrant': 0, 'disability': 0, 'none': 0.7202797202797202}, 'macro_precision': 0.4389962106942987, 'macro_recall': 0.4340056105414827, 'macro_f1_score': 0.4330003490734678}
Loading checkpoint from checkpoints/checkpoint-48050...
checkpoints/checkpoint-48050
Accuracy on valid predictions: 0.69

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.74      0.79      0.77       593
      normal       0.75      0.73      0.74       781
   offensive       0.54      0.53      0.53       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.69      1922
   macro avg       0.51      0.51      0.51      1922
weighted avg       0.69      0.69      0.69      1922

{'average_precision': 0.6934183142559833, 'average_recall': 0.682882414151925, 'overall_precision': 0.6855550394797957, 'overall_recall': 0.7133881101981634, 'f1_score': 0.6991946944576032, 'per_label_precision': {'african': 0.7872340425531915, 'arab': 0.7195121951219512, 'asian': 0.5777777777777777, 'caucasian': 0.40425531914893614, 'christian': 0.0, 'hispanic': 0.7380952380952381, 'buddhism': 0, 'hindu': 0.0, 'islam': 0.7953488372093023, 'jewish': 0.8606965174129353, 'men': 0.25, 'women': 0.47096774193548385, 'heterosexual': 0, 'homosexual': 0.7513227513227513, 'indigenous': 0, 'refugee': 0.6206896551724138, 'immigrant': 0, 'disability': 0.0, 'none': 0.7076205287713841}, 'per_label_recall': {'african': 0.8354838709677419, 'arab': 0.7662337662337663, 'asian': 0.7647058823529411, 'caucasian': 0.3958333333333333, 'christian': 0.0, 'hispanic': 0.8857142857142857, 'buddhism': 0, 'hindu': 0, 'islam': 0.8382352941176471, 'jewish': 0.9301075268817204, 'men': 0.16666666666666666, 'women': 0.48344370860927155, 'heterosexual': 0, 'homosexual': 0.7802197802197802, 'indigenous': 0, 'refugee': 0.7012987012987013, 'immigrant': 0, 'disability': 0.0, 'none': 0.6811377245508982}, 'per_label_f1': {'african': 0.8106416275430361, 'arab': 0.7421383647798743, 'asian': 0.6582278481012658, 'caucasian': 0.39999999999999997, 'christian': 0, 'hispanic': 0.8051948051948051, 'buddhism': 0, 'hindu': 0, 'islam': 0.8162291169451074, 'jewish': 0.8940568475452197, 'men': 0.2, 'women': 0.4771241830065359, 'heterosexual': 0, 'homosexual': 0.765498652291105, 'indigenous': 0, 'refugee': 0.6585365853658537, 'immigrant': 0, 'disability': 0, 'none': 0.6941266209000762}, 'macro_precision': 0.4043958212905982, 'macro_recall': 0.4331095021550923, 'macro_f1_score': 0.41693550798278306}
Loading checkpoint from checkpoints/checkpoint-52855...
checkpoints/checkpoint-52855
Accuracy on valid predictions: 0.70

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.77      0.76      0.76       593
      normal       0.75      0.76      0.75       781
   offensive       0.54      0.54      0.54       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.70      1922
   macro avg       0.51      0.51      0.51      1922
weighted avg       0.70      0.70      0.70      1922

{'average_precision': 0.6971904266389177, 'average_recall': 0.6911377037807839, 'overall_precision': 0.6952292728114868, 'overall_recall': 0.7254712421459643, 'f1_score': 0.7100283822138128, 'per_label_precision': {'african': 0.8301282051282052, 'arab': 0.7142857142857143, 'asian': 0.6388888888888888, 'caucasian': 0.4107142857142857, 'christian': 0.0, 'hispanic': 0.7837837837837838, 'buddhism': 0, 'hindu': 0, 'islam': 0.7844036697247706, 'jewish': 0.8636363636363636, 'men': 0.5, 'women': 0.535483870967742, 'heterosexual': 0, 'homosexual': 0.7251184834123223, 'indigenous': 0, 'refugee': 0.68, 'immigrant': 0, 'disability': 0.3333333333333333, 'none': 0.7177914110429447}, 'per_label_recall': {'african': 0.8354838709677419, 'arab': 0.7142857142857143, 'asian': 0.6764705882352942, 'caucasian': 0.4791666666666667, 'christian': 0.0, 'hispanic': 0.8285714285714286, 'buddhism': 0, 'hindu': 0, 'islam': 0.8382352941176471, 'jewish': 0.9193548387096774, 'men': 0.16666666666666666, 'women': 0.5496688741721855, 'heterosexual': 0, 'homosexual': 0.8406593406593407, 'indigenous': 0, 'refugee': 0.6623376623376623, 'immigrant': 0, 'disability': 0.5, 'none': 0.7005988023952096}, 'per_label_f1': {'african': 0.8327974276527331, 'arab': 0.7142857142857143, 'asian': 0.6571428571428571, 'caucasian': 0.44230769230769235, 'christian': 0, 'hispanic': 0.8055555555555555, 'buddhism': 0, 'hindu': 0, 'islam': 0.8104265402843602, 'jewish': 0.890625, 'men': 0.25, 'women': 0.542483660130719, 'heterosexual': 0, 'homosexual': 0.7786259541984734, 'indigenous': 0, 'refugee': 0.6710526315789473, 'immigrant': 0, 'disability': 0.4, 'none': 0.709090909090909}, 'macro_precision': 0.4482930531535975, 'macro_recall': 0.45849998672553854, 'macro_f1_score': 0.44759968116989274}
Loading checkpoint from checkpoints/checkpoint-57660...
checkpoints/checkpoint-57660
Accuracy on valid predictions: 0.70

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.68      0.87      0.76       593
      normal       0.80      0.71      0.75       781
   offensive       0.58      0.50      0.54       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.70      1922
   macro avg       0.51      0.52      0.51      1922
weighted avg       0.70      0.70      0.69      1922

{'average_precision': 0.7025580992022199, 'average_recall': 0.6867672563302115, 'overall_precision': 0.6968411126826969, 'overall_recall': 0.7143547607539874, 'f1_score': 0.7054892601431981, 'per_label_precision': {'african': 0.782608695652174, 'arab': 0.7205882352941176, 'asian': 0.5625, 'caucasian': 0.5185185185185185, 'christian': 0.0, 'hispanic': 0.6842105263157895, 'buddhism': 0, 'hindu': 0, 'islam': 0.7782608695652173, 'jewish': 0.8431372549019608, 'men': 0.0, 'women': 0.5294117647058824, 'heterosexual': 0, 'homosexual': 0.7169811320754716, 'indigenous': 0, 'refugee': 0.651685393258427, 'immigrant': 0, 'disability': 0.16666666666666666, 'none': 0.7010785824345146}, 'per_label_recall': {'african': 0.8709677419354839, 'arab': 0.6363636363636364, 'asian': 0.5294117647058824, 'caucasian': 0.2916666666666667, 'christian': 0.0, 'hispanic': 0.7428571428571429, 'buddhism': 0, 'hindu': 0, 'islam': 0.8774509803921569, 'jewish': 0.9247311827956989, 'men': 0.0, 'women': 0.4768211920529801, 'heterosexual': 0, 'homosexual': 0.8351648351648352, 'indigenous': 0, 'refugee': 0.7532467532467533, 'immigrant': 0, 'disability': 0.25, 'none': 0.6811377245508982}, 'per_label_f1': {'african': 0.8244274809160306, 'arab': 0.6758620689655173, 'asian': 0.5454545454545455, 'caucasian': 0.37333333333333335, 'christian': 0, 'hispanic': 0.7123287671232877, 'buddhism': 0, 'hindu': 0, 'islam': 0.8248847926267281, 'jewish': 0.882051282051282, 'men': 0, 'women': 0.5017421602787456, 'heterosexual': 0, 'homosexual': 0.7715736040609137, 'indigenous': 0, 'refugee': 0.6987951807228916, 'immigrant': 0, 'disability': 0.2, 'none': 0.6909643128321943}, 'macro_precision': 0.40292882312572315, 'macro_recall': 0.41420103267011227, 'macro_f1_score': 0.4053377646508142}
Loading checkpoint from checkpoints/checkpoint-62465...
checkpoints/checkpoint-62465
Accuracy on valid predictions: 0.69

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.75      0.77      0.76       593
      normal       0.75      0.73      0.74       781
   offensive       0.54      0.55      0.55       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.69      1922
   macro avg       0.51      0.51      0.51      1922
weighted avg       0.69      0.69      0.69      1922

{'average_precision': 0.7039542143600416, 'average_recall': 0.6886749913284772, 'overall_precision': 0.6989651928504234, 'overall_recall': 0.7182213629772837, 'f1_score': 0.7084624553039333, 'per_label_precision': {'african': 0.7981366459627329, 'arab': 0.7037037037037037, 'asian': 0.6, 'caucasian': 0.4418604651162791, 'christian': 0.0, 'hispanic': 0.725, 'buddhism': 0, 'hindu': 0.0, 'islam': 0.8009478672985783, 'jewish': 0.8434343434343434, 'men': 0.0, 'women': 0.5031055900621118, 'heterosexual': 0, 'homosexual': 0.7807486631016043, 'indigenous': 0, 'refugee': 0.6582278481012658, 'immigrant': 0, 'disability': 0.0, 'none': 0.6945668135095447}, 'per_label_recall': {'african': 0.8290322580645161, 'arab': 0.7402597402597403, 'asian': 0.6176470588235294, 'caucasian': 0.3958333333333333, 'christian': 0.0, 'hispanic': 0.8285714285714286, 'buddhism': 0, 'hindu': 0, 'islam': 0.8284313725490197, 'jewish': 0.8978494623655914, 'men': 0.0, 'women': 0.5364238410596026, 'heterosexual': 0, 'homosexual': 0.8021978021978022, 'indigenous': 0, 'refugee': 0.6753246753246753, 'immigrant': 0, 'disability': 0.0, 'none': 0.7080838323353293}, 'per_label_f1': {'african': 0.8132911392405062, 'arab': 0.7215189873417721, 'asian': 0.608695652173913, 'caucasian': 0.4175824175824176, 'christian': 0, 'hispanic': 0.7733333333333333, 'buddhism': 0, 'hindu': 0, 'islam': 0.8144578313253013, 'jewish': 0.8697916666666666, 'men': 0, 'women': 0.5192307692307693, 'heterosexual': 0, 'homosexual': 0.7913279132791329, 'indigenous': 0, 'refugee': 0.6666666666666666, 'immigrant': 0, 'disability': 0, 'none': 0.7012601927353596}, 'macro_precision': 0.3973543126468508, 'macro_recall': 0.4136660423623456, 'macro_f1_score': 0.4051135036618863}
Loading checkpoint from checkpoints/checkpoint-67270...
checkpoints/checkpoint-67270
Accuracy on valid predictions: 0.70

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.73      0.80      0.76       593
      normal       0.74      0.76      0.75       781
   offensive       0.58      0.49      0.53       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.70      1922
   macro avg       0.51      0.51      0.51      1922
weighted avg       0.69      0.70      0.69      1922

{'average_precision': 0.7004595907041277, 'average_recall': 0.6934183142559833, 'overall_precision': 0.695308871342313, 'overall_recall': 0.7235379410343161, 'f1_score': 0.7091425864519185, 'per_label_precision': {'african': 0.8074534161490683, 'arab': 0.6744186046511628, 'asian': 0.6216216216216216, 'caucasian': 0.5833333333333334, 'christian': 0.0, 'hispanic': 0.7368421052631579, 'buddhism': 0, 'hindu': 0, 'islam': 0.8195876288659794, 'jewish': 0.8617021276595744, 'men': 0.25, 'women': 0.5329341317365269, 'heterosexual': 0, 'homosexual': 0.7405660377358491, 'indigenous': 0, 'refugee': 0.6021505376344086, 'immigrant': 0, 'disability': 0.1, 'none': 0.6858789625360231}, 'per_label_recall': {'african': 0.8387096774193549, 'arab': 0.7532467532467533, 'asian': 0.6764705882352942, 'caucasian': 0.2916666666666667, 'christian': 0.0, 'hispanic': 0.8, 'buddhism': 0, 'hindu': 0, 'islam': 0.7794117647058824, 'jewish': 0.8709677419354839, 'men': 0.16666666666666666, 'women': 0.5894039735099338, 'heterosexual': 0, 'homosexual': 0.8626373626373627, 'indigenous': 0, 'refugee': 0.7272727272727273, 'immigrant': 0, 'disability': 0.25, 'none': 0.7125748502994012}, 'per_label_f1': {'african': 0.8227848101265821, 'arab': 0.7116564417177915, 'asian': 0.6478873239436619, 'caucasian': 0.38888888888888895, 'christian': 0, 'hispanic': 0.7671232876712328, 'buddhism': 0, 'hindu': 0, 'islam': 0.7989949748743718, 'jewish': 0.8663101604278075, 'men': 0.2, 'women': 0.559748427672956, 'heterosexual': 0, 'homosexual': 0.7969543147208122, 'indigenous': 0, 'refugee': 0.6588235294117646, 'immigrant': 0, 'disability': 0.14285714285714288, 'none': 0.6989720998531571}, 'macro_precision': 0.4219204477466687, 'macro_recall': 0.43784361961029095, 'macro_f1_score': 0.4242632316929563}
Loading checkpoint from checkpoints/checkpoint-72075...
checkpoints/checkpoint-72075
Accuracy on valid predictions: 0.69

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.77      0.77      0.77       593
      normal       0.73      0.72      0.73       781
   offensive       0.55      0.56      0.56       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.69      1922
   macro avg       0.51      0.52      0.52      1922
weighted avg       0.69      0.69      0.69      1922

{'average_precision': 0.7003902185223725, 'average_recall': 0.6955515088449531, 'overall_precision': 0.691847075080608, 'overall_recall': 0.7259545674238763, 'f1_score': 0.7084905660377359, 'per_label_precision': {'african': 0.7927927927927928, 'arab': 0.6703296703296703, 'asian': 0.6052631578947368, 'caucasian': 0.5, 'christian': 0.0, 'hispanic': 0.725, 'buddhism': 0, 'hindu': 0.0, 'islam': 0.7678571428571429, 'jewish': 0.8461538461538461, 'men': 0.3333333333333333, 'women': 0.5099337748344371, 'heterosexual': 0, 'homosexual': 0.7604166666666666, 'indigenous': 0, 'refugee': 0.6022727272727273, 'immigrant': 0, 'disability': 0.0, 'none': 0.6915351506456241}, 'per_label_recall': {'african': 0.8516129032258064, 'arab': 0.7922077922077922, 'asian': 0.6764705882352942, 'caucasian': 0.375, 'christian': 0.0, 'hispanic': 0.8285714285714286, 'buddhism': 0, 'hindu': 0, 'islam': 0.8431372549019608, 'jewish': 0.8870967741935484, 'men': 0.16666666666666666, 'women': 0.5099337748344371, 'heterosexual': 0, 'homosexual': 0.8021978021978022, 'indigenous': 0, 'refugee': 0.6883116883116883, 'immigrant': 0, 'disability': 0.0, 'none': 0.7215568862275449}, 'per_label_f1': {'african': 0.8211508553654744, 'arab': 0.7261904761904762, 'asian': 0.6388888888888888, 'caucasian': 0.42857142857142855, 'christian': 0, 'hispanic': 0.7733333333333333, 'buddhism': 0, 'hindu': 0, 'islam': 0.8037383177570093, 'jewish': 0.8661417322834646, 'men': 0.2222222222222222, 'women': 0.5099337748344371, 'heterosexual': 0, 'homosexual': 0.7807486631016043, 'indigenous': 0, 'refugee': 0.6424242424242423, 'immigrant': 0, 'disability': 0, 'none': 0.7062271062271063}, 'macro_precision': 0.4107835927779462, 'macro_recall': 0.4285665031354721, 'macro_f1_score': 0.41681952848419407}
Loading checkpoint from checkpoints/checkpoint-76880...
checkpoints/checkpoint-76880
Accuracy on valid predictions: 0.70

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.78      0.76      0.77       593
      normal       0.74      0.75      0.74       781
   offensive       0.55      0.55      0.55       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.70      1922
   macro avg       0.52      0.51      0.52      1922
weighted avg       0.70      0.70      0.70      1922

{'average_precision': 0.7054717308359348, 'average_recall': 0.6967568505029483, 'overall_precision': 0.7007469654528478, 'overall_recall': 0.7254712421459643, 'f1_score': 0.7128947993350748, 'per_label_precision': {'african': 0.8105590062111802, 'arab': 0.7037037037037037, 'asian': 0.6470588235294118, 'caucasian': 0.5, 'christian': 0.0, 'hispanic': 0.7368421052631579, 'buddhism': 0, 'hindu': 0.0, 'islam': 0.819047619047619, 'jewish': 0.8666666666666667, 'men': 0.2, 'women': 0.5503875968992248, 'heterosexual': 0, 'homosexual': 0.7233009708737864, 'indigenous': 0, 'refugee': 0.6138613861386139, 'immigrant': 0, 'disability': 0.0, 'none': 0.7023460410557185}, 'per_label_recall': {'african': 0.8419354838709677, 'arab': 0.7402597402597403, 'asian': 0.6470588235294118, 'caucasian': 0.4166666666666667, 'christian': 0.0, 'hispanic': 0.8, 'buddhism': 0, 'hindu': 0, 'islam': 0.8431372549019608, 'jewish': 0.9086021505376344, 'men': 0.16666666666666666, 'women': 0.47019867549668876, 'heterosexual': 0, 'homosexual': 0.8186813186813187, 'indigenous': 0, 'refugee': 0.8051948051948052, 'immigrant': 0, 'disability': 0.0, 'none': 0.7170658682634731}, 'per_label_f1': {'african': 0.8259493670886076, 'arab': 0.7215189873417721, 'asian': 0.6470588235294118, 'caucasian': 0.45454545454545453, 'christian': 0, 'hispanic': 0.7671232876712328, 'buddhism': 0, 'hindu': 0, 'islam': 0.8309178743961353, 'jewish': 0.8871391076115485, 'men': 0.1818181818181818, 'women': 0.5071428571428571, 'heterosexual': 0, 'homosexual': 0.7680412371134021, 'indigenous': 0, 'refugee': 0.696629213483146, 'immigrant': 0, 'disability': 0, 'none': 0.7096296296296297}, 'macro_precision': 0.41440915365205694, 'macro_recall': 0.4302877607404912, 'macro_f1_score': 0.4209217905984936}
Loading checkpoint from checkpoints/checkpoint-81685...
checkpoints/checkpoint-81685
Accuracy on valid predictions: 0.69

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.73      0.80      0.77       593
      normal       0.80      0.66      0.72       781
   offensive       0.53      0.61      0.57       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.69      1922
   macro avg       0.52      0.52      0.51      1922
weighted avg       0.70      0.69      0.69      1922

{'average_precision': 0.7062695109261187, 'average_recall': 0.7007891085674645, 'overall_precision': 0.7001388246182323, 'overall_recall': 0.7312711454809087, 'f1_score': 0.7153664302600473, 'per_label_precision': {'african': 0.7852941176470588, 'arab': 0.6941176470588235, 'asian': 0.6666666666666666, 'caucasian': 0.5, 'christian': 0.0, 'hispanic': 0.7631578947368421, 'buddhism': 0, 'hindu': 0.0, 'islam': 0.7763157894736842, 'jewish': 0.8622448979591837, 'men': 0.0, 'women': 0.5301204819277109, 'heterosexual': 0, 'homosexual': 0.7391304347826086, 'indigenous': 0, 'refugee': 0.6153846153846154, 'immigrant': 0, 'disability': 0.0, 'none': 0.7105666156202144}, 'per_label_recall': {'african': 0.8612903225806452, 'arab': 0.7662337662337663, 'asian': 0.6470588235294118, 'caucasian': 0.375, 'christian': 0.0, 'hispanic': 0.8285714285714286, 'buddhism': 0, 'hindu': 0, 'islam': 0.8676470588235294, 'jewish': 0.9086021505376344, 'men': 0.0, 'women': 0.5827814569536424, 'heterosexual': 0, 'homosexual': 0.8406593406593407, 'indigenous': 0, 'refugee': 0.7272727272727273, 'immigrant': 0, 'disability': 0.0, 'none': 0.6946107784431138}, 'per_label_f1': {'african': 0.8215384615384617, 'arab': 0.7283950617283951, 'asian': 0.6567164179104478, 'caucasian': 0.42857142857142855, 'christian': 0, 'hispanic': 0.7945205479452055, 'buddhism': 0, 'hindu': 0, 'islam': 0.8194444444444444, 'jewish': 0.8848167539267016, 'men': 0, 'women': 0.555205047318612, 'heterosexual': 0, 'homosexual': 0.7866323907455014, 'indigenous': 0, 'refugee': 0.6666666666666667, 'immigrant': 0, 'disability': 0, 'none': 0.7024981074943224}, 'macro_precision': 0.4022631137503899, 'macro_recall': 0.42630146597922314, 'macro_f1_score': 0.4128950172784309}
Loading checkpoint from checkpoints/checkpoint-86490...
checkpoints/checkpoint-86490
Accuracy on valid predictions: 0.69

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.74      0.80      0.77       593
      normal       0.78      0.69      0.73       781
   offensive       0.54      0.58      0.56       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.69      1922
   macro avg       0.51      0.52      0.51      1922
weighted avg       0.70      0.69      0.69      1922

{'average_precision': 0.6998352410683317, 'average_recall': 0.693097467915366, 'overall_precision': 0.6943799349744543, 'overall_recall': 0.722571290478492, 'f1_score': 0.7081951681667457, 'per_label_precision': {'african': 0.7719298245614035, 'arab': 0.725, 'asian': 0.6388888888888888, 'caucasian': 0.45652173913043476, 'christian': 0.0, 'hispanic': 0.717948717948718, 'buddhism': 0, 'hindu': 0.0, 'islam': 0.7972350230414746, 'jewish': 0.8666666666666667, 'men': 0.0, 'women': 0.5208333333333334, 'heterosexual': 0, 'homosexual': 0.7303921568627451, 'indigenous': 0, 'refugee': 0.6354166666666666, 'immigrant': 0, 'disability': 0.0, 'none': 0.7070552147239264}, 'per_label_recall': {'african': 0.8516129032258064, 'arab': 0.7532467532467533, 'asian': 0.6764705882352942, 'caucasian': 0.4375, 'christian': 0.0, 'hispanic': 0.8, 'buddhism': 0, 'hindu': 0, 'islam': 0.8480392156862745, 'jewish': 0.9086021505376344, 'men': 0.0, 'women': 0.4966887417218543, 'heterosexual': 0, 'homosexual': 0.8186813186813187, 'indigenous': 0, 'refugee': 0.7922077922077922, 'immigrant': 0, 'disability': 0.0, 'none': 0.6901197604790419}, 'per_label_f1': {'african': 0.8098159509202454, 'arab': 0.7388535031847133, 'asian': 0.6571428571428571, 'caucasian': 0.44680851063829785, 'christian': 0, 'hispanic': 0.7567567567567569, 'buddhism': 0, 'hindu': 0, 'islam': 0.8218527315914489, 'jewish': 0.8871391076115485, 'men': 0, 'women': 0.5084745762711865, 'heterosexual': 0, 'homosexual': 0.7720207253886011, 'indigenous': 0, 'refugee': 0.7052023121387284, 'immigrant': 0, 'disability': 0, 'none': 0.6984848484848485}, 'macro_precision': 0.3983099069381188, 'macro_recall': 0.42490364336956676, 'macro_f1_score': 0.41066062526995956}
Loading checkpoint from checkpoints/checkpoint-91295...
checkpoints/checkpoint-91295
Accuracy on valid predictions: 0.70

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.76      0.79      0.77       593
      normal       0.77      0.72      0.74       781
   offensive       0.55      0.57      0.56       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.70      1922
   macro avg       0.52      0.52      0.52      1922
weighted avg       0.70      0.70      0.70      1922

{'average_precision': 0.7088969823100937, 'average_recall': 0.6994710371141172, 'overall_precision': 0.7040673211781207, 'overall_recall': 0.7278878685355245, 'f1_score': 0.7157794676806083, 'per_label_precision': {'african': 0.7987616099071208, 'arab': 0.7125, 'asian': 0.696969696969697, 'caucasian': 0.5428571428571428, 'christian': 0.0, 'hispanic': 0.7297297297297297, 'buddhism': 0, 'hindu': 0, 'islam': 0.8009259259259259, 'jewish': 0.8842105263157894, 'men': 0.0, 'women': 0.5100671140939598, 'heterosexual': 0, 'homosexual': 0.7345971563981043, 'indigenous': 0, 'refugee': 0.6451612903225806, 'immigrant': 0, 'disability': 0.16666666666666666, 'none': 0.7093889716840537}, 'per_label_recall': {'african': 0.832258064516129, 'arab': 0.7402597402597403, 'asian': 0.6764705882352942, 'caucasian': 0.3958333333333333, 'christian': 0.0, 'hispanic': 0.7714285714285715, 'buddhism': 0, 'hindu': 0, 'islam': 0.8480392156862745, 'jewish': 0.9032258064516129, 'men': 0.0, 'women': 0.5033112582781457, 'heterosexual': 0, 'homosexual': 0.8516483516483516, 'indigenous': 0, 'refugee': 0.7792207792207793, 'immigrant': 0, 'disability': 0.25, 'none': 0.7125748502994012}, 'per_label_f1': {'african': 0.815165876777251, 'arab': 0.7261146496815287, 'asian': 0.6865671641791046, 'caucasian': 0.4578313253012048, 'christian': 0, 'hispanic': 0.75, 'buddhism': 0, 'hindu': 0, 'islam': 0.8238095238095239, 'jewish': 0.8936170212765957, 'men': 0, 'women': 0.5066666666666667, 'heterosexual': 0, 'homosexual': 0.7888040712468194, 'indigenous': 0, 'refugee': 0.7058823529411764, 'immigrant': 0, 'disability': 0.2, 'none': 0.7109783420463032}, 'macro_precision': 0.41746504373004056, 'macro_recall': 0.4349616083872439, 'macro_f1_score': 0.4244966838908513}
Loading checkpoint from checkpoints/checkpoint-9610...
checkpoints/checkpoint-9610
Accuracy on valid predictions: 0.71

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.75      0.80      0.77       593
      normal       0.78      0.72      0.75       781
   offensive       0.56      0.58      0.57       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.71      1922
   macro avg       0.52      0.53      0.52      1922
weighted avg       0.71      0.71      0.71      1922

{'average_precision': 0.6891085674644468, 'average_recall': 0.6822233784252514, 'overall_precision': 0.6810661764705882, 'overall_recall': 0.7162880618656355, 'f1_score': 0.6982332155477032, 'per_label_precision': {'african': 0.783625730994152, 'arab': 0.6707317073170732, 'asian': 0.6216216216216216, 'caucasian': 0.3333333333333333, 'christian': 0.0, 'hispanic': 0.7567567567567568, 'buddhism': 0, 'hindu': 0, 'islam': 0.8421052631578947, 'jewish': 0.8439024390243902, 'men': 0.3333333333333333, 'women': 0.5029940119760479, 'heterosexual': 0, 'homosexual': 0.7671957671957672, 'indigenous': 0, 'refugee': 0.6419753086419753, 'immigrant': 0, 'disability': 0.2, 'none': 0.7110754414125201}, 'per_label_recall': {'african': 0.864516129032258, 'arab': 0.7142857142857143, 'asian': 0.6764705882352942, 'caucasian': 0.375, 'christian': 0.0, 'hispanic': 0.8, 'buddhism': 0, 'hindu': 0, 'islam': 0.8627450980392157, 'jewish': 0.9301075268817204, 'men': 0.16666666666666666, 'women': 0.5562913907284768, 'heterosexual': 0, 'homosexual': 0.7967032967032966, 'indigenous': 0, 'refugee': 0.6753246753246753, 'immigrant': 0, 'disability': 0.25, 'none': 0.6631736526946108}, 'per_label_f1': {'african': 0.8220858895705522, 'arab': 0.6918238993710693, 'asian': 0.6478873239436619, 'caucasian': 0.35294117647058826, 'christian': 0, 'hispanic': 0.7777777777777778, 'buddhism': 0, 'hindu': 0, 'islam': 0.8523002421307506, 'jewish': 0.8849104859335037, 'men': 0.2222222222222222, 'women': 0.5283018867924528, 'heterosexual': 0, 'homosexual': 0.7816711590296495, 'indigenous': 0, 'refugee': 0.6582278481012659, 'immigrant': 0, 'disability': 0.22222222222222224, 'none': 0.6862896979085981}, 'macro_precision': 0.4215079323560456, 'macro_recall': 0.4384886704522068, 'macro_f1_score': 0.42782430691970075}

Loading checkpoint from /bigdata/rhome/sfaa2021/mistral/checkpoints/mistral_regular/checkpoint-96100...
/bigdata/rhome/sfaa2021/mistral/checkpoints/mistral_regular/checkpoint-96100
Accuracy on valid predictions: 0.70

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.76      0.78      0.77       593
      normal       0.76      0.73      0.74       781
   offensive       0.56      0.57      0.56       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.70      1922
   macro avg       0.52      0.52      0.52      1922
weighted avg       0.70      0.70      0.70      1922

{'average_precision': 0.7024800554977454, 'average_recall': 0.6943548387096773, 'overall_precision': 0.6975768872320597, 'overall_recall': 0.7235379410343161, 'f1_score': 0.710320284697509, 'per_label_precision': {'african': 0.7907692307692308, 'arab': 0.7125, 'asian': 0.696969696969697, 'caucasian': 0.5, 'christian': 0.0, 'hispanic': 0.7297297297297297, 'buddhism': 0, 'hindu': 0.0, 'islam': 0.7952380952380952, 'jewish': 0.8704663212435233, 'men': 0.0, 'women': 0.5064102564102564, 'heterosexual': 0, 'homosexual': 0.7450980392156863, 'indigenous': 0, 'refugee': 0.648936170212766, 'immigrant': 0, 'disability': 0.16666666666666666, 'none': 0.7001477104874446}, 'per_label_recall': {'african': 0.8290322580645161, 'arab': 0.7402597402597403, 'asian': 0.6764705882352942, 'caucasian': 0.375, 'christian': 0.0, 'hispanic': 0.7714285714285715, 'buddhism': 0, 'hindu': 0, 'islam': 0.8186274509803921, 'jewish': 0.9032258064516129, 'men': 0.0, 'women': 0.5231788079470199, 'heterosexual': 0, 'homosexual': 0.8351648351648352, 'indigenous': 0, 'refugee': 0.7922077922077922, 'immigrant': 0, 'disability': 0.25, 'none': 0.7095808383233533}, 'per_label_f1': {'african': 0.8094488188976378, 'arab': 0.7261146496815287, 'asian': 0.6865671641791046, 'caucasian': 0.42857142857142855, 'christian': 0, 'hispanic': 0.75, 'buddhism': 0, 'hindu': 0, 'islam': 0.8067632850241545, 'jewish': 0.8865435356200527, 'men': 0, 'women': 0.514657980456026, 'heterosexual': 0, 'homosexual': 0.7875647668393781, 'indigenous': 0, 'refugee': 0.7134502923976609, 'immigrant': 0, 'disability': 0.2, 'none': 0.7048327137546467}, 'macro_precision': 0.4138385219443735, 'macro_recall': 0.43285140468753297, 'macro_f1_score': 0.4218165597590326}
Successfully processed /bigdata/rhome/sfaa2021/mistral/checkpoints/mistral_regular/checkpoint-96100
Loading checkpoint from /bigdata/rhome/sfaa2021/mistral/checkpoints/mistral_regular/checkpoint-91295...
/bigdata/rhome/sfaa2021/mistral/checkpoints/mistral_regular/checkpoint-91295
Accuracy on valid predictions: 0.70

Classification Report:

              precision    recall  f1-score   support

 hate speech       0.76      0.79      0.77       593
      normal       0.77      0.72      0.74       781
   offensive       0.55      0.57      0.56       548
   undecided       0.00      0.00      0.00         0

    accuracy                           0.70      1922
   macro avg       0.52      0.52      0.52      1922
weighted avg       0.70      0.70      0.70      1922

{'average_precision': 0.7088969823100937, 'average_recall': 0.6994710371141172, 'overall_precision': 0.7040673211781207, 'overall_recall': 0.7278878685355245, 'f1_score': 0.7157794676806083, 'per_label_precision': {'african': 0.7987616099071208, 'arab': 0.7125, 'asian': 0.696969696969697, 'caucasian': 0.5428571428571428, 'christian': 0.0, 'hispanic': 0.7297297297297297, 'buddhism': 0, 'hindu': 0, 'islam': 0.8009259259259259, 'jewish': 0.8842105263157894, 'men': 0.0, 'women': 0.5100671140939598, 'heterosexual': 0, 'homosexual': 0.7345971563981043, 'indigenous': 0, 'refugee': 0.6451612903225806, 'immigrant': 0, 'disability': 0.16666666666666666, 'none': 0.7093889716840537}, 'per_label_recall': {'african': 0.832258064516129, 'arab': 0.7402597402597403, 'asian': 0.6764705882352942, 'caucasian': 0.3958333333333333, 'christian': 0.0, 'hispanic': 0.7714285714285715, 'buddhism': 0, 'hindu': 0, 'islam': 0.8480392156862745, 'jewish': 0.9032258064516129, 'men': 0.0, 'women': 0.5033112582781457, 'heterosexual': 0, 'homosexual': 0.8516483516483516, 'indigenous': 0, 'refugee': 0.7792207792207793, 'immigrant': 0, 'disability': 0.25, 'none': 0.7125748502994012}, 'per_label_f1': {'african': 0.815165876777251, 'arab': 0.7261146496815287, 'asian': 0.6865671641791046, 'caucasian': 0.4578313253012048, 'christian': 0, 'hispanic': 0.75, 'buddhism': 0, 'hindu': 0, 'islam': 0.8238095238095239, 'jewish': 0.8936170212765957, 'men': 0, 'women': 0.5066666666666667, 'heterosexual': 0, 'homosexual': 0.7888040712468194, 'indigenous': 0, 'refugee': 0.7058823529411764, 'immigrant': 0, 'disability': 0.2, 'none': 0.7109783420463032}, 'macro_precision': 0.41746504373004056, 'macro_recall': 0.4349616083872439, 'macro_f1_score': 0.4244966838908513}
Successfully processed /bigdata/rhome/sfaa2021/mistral/checkpoints/mistral_regular/checkpoint-91295
